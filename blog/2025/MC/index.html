<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Monte Carlo Simulations (MC) | Tianyi Zhang </title> <meta name="author" content="Tianyi Zhang"> <meta name="description" content="Introduction to Monte Carlo simulation"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhangty.com/blog/2025/MC/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tianyi</span> Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Monte Carlo Simulations (MC)</h1> <p class="post-meta"> Created in June 13, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/physics"> <i class="fa-solid fa-hashtag fa-sm"></i> physics</a>   <a href="/blog/tag/mc"> <i class="fa-solid fa-hashtag fa-sm"></i> MC</a>   <a href="/blog/tag/simulation"> <i class="fa-solid fa-hashtag fa-sm"></i> simulation</a>   ·   <a href="/blog/category/computationalphysics"> <i class="fa-solid fa-tag fa-sm"></i> ComputationalPhysics</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction-to-monte-carlo">Introduction to Monte Carlo</h2> <p>Methods which make use of <strong>random numbers</strong> are often called <em>Monte Carlo Methods</em> named after the Casino Monte Carlo in Monaco which has long been famous for games of chance. MC methods vary, bute tend to follow a particular pattern:</p> <ul> <li>Define a domain of possible inputs</li> <li>Generate inputs randomly from a probability distribution</li> <li>Perform a deterministic computation on the inputs.</li> <li>Aggregate the results.</li> </ul> <h2 id="math-foundation-of-mc-methods">Math Foundation of MC Methods</h2> <h3 id="1-law-of-large-numbers-lln">1. Law of Large Numbers (LLN)</h3> <p>Assume \(\xi_1, \xi_2, ..., \xi_n\) is a random i.i.d. variable series, with math expectation \(E(xi_i) = \mu\). Then for arbitrary \(\epsilon &gt; 0\), there is: \begin{equation} \lim_{n \to \infty} p \lbrace |\frac{1}{n}\sum_{i=1}^{n} \xi_i-\mu| &lt; \epsilon \rbrace = 1. \end{equation} This means when \(n\) goes large, the average of samples convert to math expectation.</p> <h3 id="2-central-limit-theorem-clt">2. Central Limit Theorem (CLT)</h3> <p>In addition to above, if the square difference \(D(\xi_i) = \sigma^2\), then for arbitrary real number \(\lambda\): \begin{equation} \lim_{n \to \infty} p \lbrace \frac{\frac{1}{n}\sum_{i=1}^n \xi_i-\mu}{\sigma / \sqrt{n}} &lt; \lambda \rbrace = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\lambda e^{-(x^2 /2)} dx, \end{equation} which means when \(n\) goes large, the mean value of i.i.d. random variables approximately follows a normal distribution with average \(\mu\) and square difference \(\sigma^2 /n\).</p> <h2 id="mc-evaluation-of-statistical-mechanics-integrals">MC Evaluation of Statistical Mechanics Integrals</h2> <p>Ensemble average of quantity \(A(r,p)\) can be calculated for a given distribution function. For \(NVT\) ensemble we have distribution function \(\rho (r,p)\), \begin{equation} \rho (\vec r^N, \vec p^N)=\frac{1}{Z}\text{exp}(-\frac{E(\vec r^N, \vec p^N)}{k_B T}) \end{equation} \begin{equation} \langle A(\vec r^N,\vec p^N)\rangle = \int A(\vec r^N, \vec p^N) \rho (\vec r^N,\vec p^N)d\vec r^N d\vec p^N. \end{equation} Energy can always be expressed as a sum of kinetic and potential contributions. The contribution of the kinetic part is trivial and we can consider intrgral in only configuration \(3N\) dimensional space, where \(Z\) is configurational integral. \begin{equation} \langle A(\vec r^N)\rangle = \frac{1}{Z} \int A(\vec r^N)\text{exp}( -\frac{U(\vec r^N)}{k_B T} ) d\vec r^N \end{equation} \begin{equation} Z=\int e^{-\frac{U(\vec r^N)}{k_B T}} d\vec r^N \end{equation}</p> <blockquote> <p><em>Statistical-mechanics integrals typically have significant contributions only from very small fractions of the 3N space. So random sampling of the configurational space is highly inefficient.</em></p> </blockquote> <h2 id="markov-chain-monte-carlo-mcmc">Markov-Chain Monte Carlo (MCMC)</h2> <p>The Markov chain Monte Carlo method takes the opposite extreme approach of generating points such that each point is directly dependent on previus one. Thus the points are correlated with each other.</p> <h3 id="markov-chain">Markov Chain</h3> <p>A <em>Markov chain</em> is a sequence of elements chosen from a fixed set according to a probabilistic rule. Given the most recently added element of the chain, the choice of the next element depends only on the most recent addition and not on the previous history of the construction process.</p> <h3 id="transition-matrix">Transition Matrix</h3> <p>Let \(P\) be the transition matrix of a Markov chain. The \(ij\)th entry \(p_{ij}^(n)\) of the matrix \(P^n\) gives the probability that the Markov chain, starting in state \(s_i\), will be in state \(s_j\) after \(n\) steps.</p> <h3 id="stationary-distribution">Stationary Distribution</h3> <p>A <em>stationary distribution</em> (also called an <em>equilibrium distribution</em>) of a Markov chain is a probability distribution \(\pi^{\ast}\) s.t. \(\pi^{\ast} = \pi^{\ast} P\). So if a chain reaches a stationary distribution, then it maintains that distribution for all future time.</p> <h3 id="random-walk">Random Walk</h3> <h4 id="statistical-behavior-of-1d-walks">Statistical Behavior of 1D Walks</h4> <p>The average over a large number of n-step walks: \begin{equation} \langle x_n\rangle=0 \end{equation} \begin{equation} \langle x_n^2\rangle = n \end{equation}</p> <h5 id="diffusion-constant-d"><em>diffusion constant \(D\)</em></h5> <p>The diffusion constant is defined by \(\langle x_n^2\rangle = 2Dn\). For this 1-D walk: \(D=\frac{1}{2}\).</p> <h4 id="continuum-limit">Continuum Limit</h4> <p>The basic random walk can be rewritten as a continuum diffusion equation by taking the limit in which the lattice spacing \(l\) and the time step \(\tau\) go to zero. From the master equation \begin{equation} P(i,N)=\frac{1}{2}P(i+1,N-1)+\frac{1}{2}P(i-1,N-1), \end{equation} we can identify \(t=N\tau\) and \(x=il\). After a series of operations we get the equation: \begin{equation} \frac{\partial P(x,t)}{\partial t}=D\frac{\partial ^2 P(x,t)}{\partial x^2}, \end{equation} where \(D=l^2/2\tau\). And we have the <em>Einstein relation</em>: \(\langle x^2(t)\rangle=2Dt\).</p> <h4 id="self-avoiding-random-walk-srw">Self-Avoiding Random Walk (SRW)</h4> <h4 id="diffusion-limited-aggregation-dla">Diffusion-Limited Aggregation (DLA)</h4> <h2 id="metropolis-monte-carlo-mmc">Metropolis Monte Carlo (MMC)</h2> <p>We want to generate points in a distribution \(f(x)\) whose probability density \(\rho(x)\) is known.</p> <p><strong>Basic Idea:</strong> construct a Markov chain and make its stationary distribution equals \(\rho (x)\).</p> <h3 id="steps-of-mmc-algorithm">Steps of MMC Algorithm</h3> <ol> <li>Initialization: <ul> <li>select an initial configuration \(x\) for which \(\rho (x)&gt;0\)</li> <li>choose a maximum displacement value \(\Delta x_{\text{max}}\)</li> <li>calculate the initial \(\rho = \rho (x)\)</li> </ul> </li> <li>Store the current state as \(x_0=x\)</li> <li>Generate a random number vector \(\vec u = (u_1,u_2,...,u_M)\) where each \(u\) is a uniform random number between \(-1\) and \(1\).</li> <li>Calculate the value of the function in the trial state \(\rho ' =\rho (x')\)</li> <li>Choose whether to move to the new state as follows (Metropolis): <ul> <li>if \(\rho '\geq \rho\): accept the state</li> <li>if \(\rho '&lt; \rho\): accept the state only if \(r &lt; \frac{\rho '}{\rho}\) where \(r\) is a random number ~Uniform\([0,1]\)</li> </ul> </li> <li>Calculate the new \(\rho = \rho (x)\)</li> <li>Do statistics of the current value of \(x\) or other properties</li> <li>return to step 2</li> </ol> <h5 id="why-this-works"><em>why this works?</em></h5> <ul> <li>Being in a minimum of \(\rho (x)\): new trial state will always be accepted.</li> <li>Being next to a minimum: we have a smaller probability of accepting the move to the minimum. Therefore, the system is more likely to go to states with larger \(\rho\) values! <blockquote> <p><em>The sequence of states are highly correlated! Thus for a low statistics this is probably a very poor way of generating points in a distribution.</em></p> </blockquote> </li> </ul> <h3 id="detailed-balance-condition">Detailed Balance Condition</h3> <p>\(P(m,t)\) is the probability of being in configuration \(m\) at time \(t\), \(W(m /to n, t)\) is the probability of going from state \(m\) to state \(n\) per unit time (transition probability). Then we have \begin{equation} P(m,t+1)=P(m,t)+\sum_n [W(n\to m)P(n,t)-W(m\to n)P(m,t)]. \end{equation} At large \(t\), clearly a sufficient (but not necessary) condition for an equilibrium probability distribution is the so-called <em>detailed balance condition</em>: \begin{equation} W(n\to m)P(n,t)=W(m\to n)P(m,t) \end{equation}</p> <p>This can be applied to any probability distribution, but if we choose the Boltzmann distribution we have \begin{equation} \label{dbc} \frac{W(m\to n)}{W(n\to m)}=\frac{P(n)}{P(m)}=\text{exp}(-\frac{U_n-U_m}{k_BT}), \end{equation} where \(Z\) does not appear.</p> <h3 id="mmc-for-ensemble-averages">MMC for Ensemble Averages</h3> <p>The MMC algorithm for ensemble: \begin{equation} W(m\to n)=\frac{\rho_n}{\rho_m}=\text{exp}(-\frac{U_{nm}}{K_BT}),U_{nm}&gt;0 \end{equation} \begin{equation} W(m\to n)=1,U_{nm}\leq 0, \end{equation} which satisfies the detailed balance condition (\(\ref{dbc}\)).</p> <p>Now the ensemble average of a physics quantity \(A\) can be calculated by math average from samples with Boltzmann distribution: \begin{equation} \langle A\rangle \approx \frac{1}{N_{\text{samples}}}\sum_{i=1}^{N_{\text{samples}}} A(\vec r_i^N). \end{equation} The key points are:</p> <ul> <li>Taking Boltzmann distribution as desired distribution: \(\rho(\vec r^N)=e^{-\frac{U(\vec r^N)}{k_BT}}\).</li> <li>Constructing sample chain with <strong>Metropolis MC</strong>.</li> <li>The weight of samples are included in sampling frequency.</li> </ul> <h2 id="lattice-monte-carlo-ising-model">Lattice Monte Carlo: Ising Model</h2> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Tianyi Zhang. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>